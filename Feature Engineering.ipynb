{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:07:31.297712Z",
     "start_time": "2019-10-29T19:07:30.348411Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import re\n",
    "# see https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "%pylab inline\n",
    "# sets backend to render higher res images\n",
    "%config InlineBackend.figure_formats = ['retina']\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Page Ahead Book Up program information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:07:31.307714Z",
     "start_time": "2019-10-29T19:07:31.299924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.defaultdict"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./data/interim/book_up_dict.pickle', 'rb') as handle:\n",
    "    bookup_dct = pickle.load(handle)\n",
    "type(bookup_dct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Map Assessment student information\n",
    "Creates map_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:07:31.545293Z",
     "start_time": "2019-10-29T19:07:31.311004Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape= (82049, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['StudentID', 'CurrentEnrollmentSchoolID', 'CurrentEnrollmentSchoolName',\n",
       "       'CurrentGrade', 'TestSchoolYear', 'TestSeason', 'TestSchoolID',\n",
       "       'TestSchoolName', 'TestGrade', 'SubjectArea', 'TestName', 'RITScore',\n",
       "       'PercentileRank', 'MetGrowthLastFallToThisFall',\n",
       "       'MetGrowthLastSpringToThisSpring', 'MetGrowthLastFallToThisSpring',\n",
       "       'BirthDate', 'Gender', 'RacialEthnicGroup', 'ELLStatus', 'IEPStatus',\n",
       "       'Student504Status', 'GiftedStatus', 'PrimaryLanguage', 'HomeLanguage',\n",
       "       'LivingWith', 'USAEntryDate', 'BirthCountry', 'ProjectedGradYear',\n",
       "       'ExtractSchoolYear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_df = pd.read_pickle(\"./data/interim/map_df.pkl\")\n",
    "print('shape=',map_df.shape)\n",
    "map_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Smarter Balance Assessment Score Information\n",
    "Creates targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:07:31.558258Z",
     "start_time": "2019-10-29T19:07:31.547895Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape= (4438, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['StudentID', 'CurrentEnrollmentSchoolID', 'CurrentEnrollmentSchoolName',\n",
       "       'CurrentGrade', 'TestSchoolYear', 'TestSeason', 'TestSchoolID',\n",
       "       'TestSchoolName', 'TestGrade', 'SubjectArea', 'TestName', 'AttemptCode',\n",
       "       'Attempt', 'Score', 'LevelCode', 'MetStandard', 'BirthDate', 'Gender',\n",
       "       'RacialEthnicGroup', 'ELLStatus', 'IEPStatus', 'Student504Status',\n",
       "       'GiftedStatus', 'PrimaryLanguage', 'HomeLanguage', 'LivingWith',\n",
       "       'USAEntryDate', 'BirthCountry', 'ProjectedGradYear',\n",
       "       'ExtractSchoolYear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_df = pd.read_pickle(\"./data/interim/targets.pkl\")\n",
    "print('shape=',targets_df.shape)\n",
    "targets_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A function that returns all the data for a given student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:07:31.563064Z",
     "start_time": "2019-10-29T19:07:31.559875Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_student_data(studentID):\n",
    "    \"\"\"Gets all records for studentID from the map_df\n",
    "    -----\n",
    "    input: a string containing the studentID\n",
    "    returns: a pandas dataframe of all columns of the map_df for studentID\n",
    "    \"\"\"\n",
    "    df = map_df[map_df.StudentID==studentID]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions used to build the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:07:31.575281Z",
     "start_time": "2019-10-29T19:07:31.564800Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_RITs(stu_data,school_year):\n",
    "    \"\"\"Gets the mean any available MAP RIT scores for each test season\n",
    "    (Fall, Winter, Spring) of the 2015-16 school year (1st Grade).\n",
    "    -----\n",
    "    Inputs: A dataframe containing all the students data from the map_df\n",
    "            and the school year in the form of '2015-16'\n",
    "    Returns: G1_Fall_RIT, G1_Winter_RIT, G1_Spring_RIT for the given year if available.\n",
    "    \"\"\"\n",
    "    G1_Fall_RIT, G1_Winter_RIT, G1_Spring_RIT = None, None, None\n",
    "    yr_data = stu_data[stu_data.TestSchoolYear==school_year]\n",
    "    RIT_by_season = yr_data.groupby(['TestSeason']).RITScore.mean()\n",
    "    for season in RIT_by_season.index:\n",
    "        if season=='Fall':\n",
    "            G1_Fall_RIT=RIT_by_season[season]\n",
    "        if season=='Spring':\n",
    "            G1_Spring_RIT=RIT_by_season[season]\n",
    "        if season=='Winter':\n",
    "            G1_Winter_RIT=RIT_by_season[season]\n",
    "    return G1_Fall_RIT, G1_Winter_RIT, G1_Spring_RIT\n",
    "\n",
    "def get_last_RIT(Fall_RIT,Winter_RIT,Spring_RIT):\n",
    "    \"\"\"Returns the RIT score from latest in the school year.\n",
    "    ---\n",
    "    input: RIT scores for Fall, Winter and Spring\n",
    "    returns: the season name and the score of the score from latest in the school year.\n",
    "    \"\"\"\n",
    "    if Spring_RIT is not None:\n",
    "        return 'Spring',Spring_RIT\n",
    "    elif Winter_RIT is not None:\n",
    "        return 'Winter',Winter_RIT\n",
    "    elif Fall_RIT is not None:\n",
    "        return 'Fall', Fall_RIT\n",
    "    return None, None\n",
    "\n",
    "def get_treatments(stu_data):\n",
    "    \"\"\"Determines a list of the year and school students would have received \n",
    "    Book Up program treatments from Page Ahead.\n",
    "    -----\n",
    "    input: A dataframe containing all rows of map_df for a given student\n",
    "    returns: A list of tuples of the year and school ID a student should have\n",
    "             received Book Up program books in the summer.\n",
    "    \"\"\"\n",
    "    treatments = []\n",
    "    # For each year of the student's data...\n",
    "    for yr in stu_data.TestSchoolYear.unique():\n",
    "        yr_data = stu_data[stu_data.TestSchoolYear==yr]\n",
    "        # Get a collection of the schools they tested at...\n",
    "        gb=yr_data.groupby(['TestSchoolID','TestGrade','TestSeason']).RITScore.mean()\n",
    "        # Determine which testing record was the last in the school year to estimate\n",
    "        # which school they were attending...\n",
    "        last = 0\n",
    "        last_ind = 0\n",
    "        for i in range(0,len(gb)):\n",
    "            position = ['Fall','Winter','Spring'].index(gb.index[i][2])\n",
    "            if position > last:\n",
    "                last_ind = i\n",
    "                last = position\n",
    "        SchoolID = gb.index[last_ind][0]\n",
    "        TestGrade = gb.index[last_ind][1]\n",
    "        # If the school they were attending was being served by the Book Up program\n",
    "        # of Page Ahead then record the year and school in the treatments list.\n",
    "        if SchoolID in bookup_dct[yr,TestGrade]:\n",
    "            treatments.append((int(yr[:4])+1,SchoolID))\n",
    "    return treatments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the X dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:07:31.584053Z",
     "start_time": "2019-10-29T19:07:31.577514Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StudentID', 'CurrentEnrollmentSchoolID', 'CurrentEnrollmentSchoolName',\n",
       "       'CurrentGrade', 'TestSchoolYear', 'TestSeason', 'TestSchoolID',\n",
       "       'TestSchoolName', 'TestGrade', 'SubjectArea', 'TestName', 'RITScore',\n",
       "       'PercentileRank', 'MetGrowthLastFallToThisFall',\n",
       "       'MetGrowthLastSpringToThisSpring', 'MetGrowthLastFallToThisSpring',\n",
       "       'BirthDate', 'Gender', 'RacialEthnicGroup', 'ELLStatus', 'IEPStatus',\n",
       "       'Student504Status', 'GiftedStatus', 'PrimaryLanguage', 'HomeLanguage',\n",
       "       'LivingWith', 'USAEntryDate', 'BirthCountry', 'ProjectedGradYear',\n",
       "       'ExtractSchoolYear'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = get_student_data(3099442)\n",
    "example.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MVP involved gathering the minimum required columns:\n",
    "* Last_G1_RIT: Last 1st Grade RIT score\n",
    "* nTreatments: The number of treatments the student should have received."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:08:25.694769Z",
     "start_time": "2019-10-29T19:07:31.588292Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4438 entries, 0 to 4437\n",
      "Data columns (total 8 columns):\n",
      "StudentID             4438 non-null object\n",
      "G1_Fall_RIT           1619 non-null object\n",
      "G1_Winter_RIT         1254 non-null object\n",
      "G1_Spring_RIT         3571 non-null object\n",
      "Last_G1_RIT           3625 non-null object\n",
      "Last_G1_RIT_Season    3625 non-null object\n",
      "Treatments            4438 non-null object\n",
      "nTreatments           4438 non-null int64\n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 277.5+ KB\n"
     ]
    }
   ],
   "source": [
    "X_df = pd.DataFrame(columns=['StudentID','G1_Fall_RIT','G1_Winter_RIT','G1_Spring_RIT',\\\n",
    "                             'Last_G1_RIT','Last_G1_RIT_Season',\\\n",
    "                             'Treatments','nTreatments'])\n",
    "for studentID in targets_df.StudentID:\n",
    "    Stu_data = get_student_data(studentID)\n",
    "    G1_Fall_RIT, G1_Winter_RIT, G1_Spring_RIT = get_RITs(Stu_data,'2015-16')\n",
    "    Last_RIT_Season, Last_RIT = get_last_RIT(G1_Fall_RIT, G1_Winter_RIT, G1_Spring_RIT)\n",
    "    treatments = get_treatments(Stu_data)\n",
    "    X_df = X_df.append({'StudentID':studentID,\n",
    "                        'G1_Fall_RIT':G1_Fall_RIT,\n",
    "                        'G1_Winter_RIT':G1_Winter_RIT,\n",
    "                        'G1_Spring_RIT':G1_Spring_RIT,\n",
    "                        'Last_G1_RIT':Last_RIT,\n",
    "                        'Last_G1_RIT_Season':Last_RIT_Season,\n",
    "                        'Treatments':treatments,\n",
    "                        'nTreatments':int(len(treatments))\n",
    "                       },ignore_index=True)\n",
    "\n",
    "X_df.nTreatments = pd.to_numeric(X_df.nTreatments)\n",
    "X_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Gender=Female Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:08:25.706379Z",
     "start_time": "2019-10-29T19:08:25.697748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Female'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = get_student_data(3099442)\n",
    "#example = pd.DataFrame(data={'Gender': [None, None, None]})\n",
    "example['Gender'].value_counts().empty\n",
    "Gender = example['Gender'].value_counts()\n",
    "Gender = None if Gender.empty else Gender.idxmax()\n",
    "Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:08:38.021554Z",
     "start_time": "2019-10-29T19:08:25.708097Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2543\n",
       "1    1895\n",
       "Name: Female, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'Female' in X_df.columns:\n",
    "    X_df.drop(['Female'], axis=1,inplace=True)\n",
    "Female = pd.DataFrame(columns=['Female'])\n",
    "for studentID in targets_df.StudentID:\n",
    "    Stu_data = get_student_data(studentID)\n",
    "    Gender = Stu_data['Gender'].value_counts()\n",
    "    Gender = None if Gender.empty else Gender.idxmax()\n",
    "    Female = Female.append({'Female':Gender},ignore_index=True)\n",
    "Female = pd.get_dummies(Female.Female)\n",
    "X_df['Female'] = Female.Female.copy()\n",
    "X_df.Female.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: 509 rows of the resulting Female dataframe are Female=0 and Male=0 (Gender was None).  So by keeping only Female.Female in the X_df I'm essentially recategorizing the None's as males!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:08:38.029590Z",
     "start_time": "2019-10-29T19:08:38.023447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(509, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Female[(Female.Female==0) & (Female.Male==0)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Home Language Is English Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:08:38.040361Z",
     "start_time": "2019-10-29T19:08:38.031121Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spanish'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = get_student_data(3099442)\n",
    "#example = pd.DataFrame(data={'HomeLanguage': [None, None, None]})\n",
    "example['HomeLanguage'].value_counts().empty\n",
    "HomeLanguage = example['HomeLanguage'].value_counts()\n",
    "HomeLanguage = None if HomeLanguage.empty else HomeLanguage.idxmax()\n",
    "HomeLanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:08:50.337781Z",
     "start_time": "2019-10-29T19:08:38.043578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3053\n",
       "0    1385\n",
       "Name: HomeLanIsEng, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'HomeLanIsEng' in X_df.columns:\n",
    "    X_df.drop(['HomeLanIsEng'], axis=1,inplace=True)\n",
    "HomeLanIsEng = pd.DataFrame(columns=['HomeLanIsEng'])\n",
    "for studentID in targets_df.StudentID:\n",
    "    Stu_data = get_student_data(studentID)\n",
    "    HomeLanguage = Stu_data['HomeLanguage'].value_counts()\n",
    "    HomeLanguage = None if HomeLanguage.empty else HomeLanguage.idxmax()\n",
    "    HomeLanIsEng = HomeLanIsEng.append({'HomeLanIsEng':HomeLanguage},ignore_index=True)\n",
    "HomeLanIsEng = pd.get_dummies(HomeLanIsEng.HomeLanIsEng)\n",
    "X_df['HomeLanIsEng'] = HomeLanIsEng.English.copy()\n",
    "X_df.HomeLanIsEng.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:08:50.343180Z",
     "start_time": "2019-10-29T19:08:50.339642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4438, 59)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HomeLanIsEng.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add A Primary Language Is English Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:08:50.353594Z",
     "start_time": "2019-10-29T19:08:50.344813Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spanish'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = get_student_data(3099442)\n",
    "#example = pd.DataFrame(data={'PrimaryLanguage': [None, None, None]})\n",
    "example['PrimaryLanguage'].value_counts().empty\n",
    "PrimaryLanguage = example['PrimaryLanguage'].value_counts()\n",
    "PrimaryLanguage = None if PrimaryLanguage.empty else PrimaryLanguage.idxmax()\n",
    "PrimaryLanguage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:03.181787Z",
     "start_time": "2019-10-29T19:08:50.357148Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3078\n",
       "0    1360\n",
       "Name: PrimaryLanIsEng, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'PrimaryLanIsEng' in X_df.columns:\n",
    "    X_df.drop(['PrimaryLanIsEng'], axis=1,inplace=True)\n",
    "PrimaryLanIsEng = pd.DataFrame(columns=['PrimaryLanIsEng'])\n",
    "for studentID in targets_df.StudentID:\n",
    "    Stu_data = get_student_data(studentID)\n",
    "    PrimaryLanguage = Stu_data['PrimaryLanguage'].value_counts()\n",
    "    PrimaryLanguage = None if PrimaryLanguage.empty else PrimaryLanguage.idxmax()\n",
    "    PrimaryLanIsEng = PrimaryLanIsEng.append({'PrimaryLanIsEng':PrimaryLanguage},ignore_index=True)\n",
    "PrimaryLanIsEng = pd.get_dummies(PrimaryLanIsEng.PrimaryLanIsEng)\n",
    "X_df['PrimaryLanIsEng'] = PrimaryLanIsEng.English.copy()\n",
    "X_df.PrimaryLanIsEng.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:03.188786Z",
     "start_time": "2019-10-29T19:09:03.183850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-English languages: 54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Afrikaans', 'Amharic', 'Arabic', 'Bikol', 'Bilen', 'Bosnian',\n",
       "       'Bulgarian', 'Burmese', 'Cakchiquel', 'Cambodian', 'Cham',\n",
       "       'Chinese-Cantonese', 'Chinese-Mandarin', 'Chinese-Taiwanese',\n",
       "       'Chinese-Unspecified', 'Creole', 'Czech', 'English', 'Estonian',\n",
       "       'Ethiopic', 'Farsi', 'French', 'Fula', 'German', 'Hebrew, Modern',\n",
       "       'Ilokano', 'Italian', 'Japanese', 'Karen', 'Khmer', 'Kikuya', 'Korean',\n",
       "       'Lao', 'Maay', 'Mandingo', 'Maya-Quiche', 'Mien', 'Mongolian', 'Oromo',\n",
       "       'Portuguese', 'Punjabi', 'Russian', 'Samoan', 'Somali', 'Soninke',\n",
       "       'Spanish', 'Swahili', 'Tagalog', 'Thai', 'Tigrinya', 'Toishanese',\n",
       "       'Ukrainian', 'Urdu', 'Vietnamese', 'Visayan'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of non-English languages:',len(PrimaryLanIsEng.columns)-1)\n",
    "PrimaryLanIsEng.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:03.196101Z",
     "start_time": "2019-10-29T19:09:03.190376Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df[(X_df.PrimaryLanIsEng==1)&(X_df.HomeLanIsEng==0)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:03.207238Z",
     "start_time": "2019-10-29T19:09:03.198603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 11)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df[(X_df.PrimaryLanIsEng==0)&(X_df.HomeLanIsEng==1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Living With Feature\n",
    "To keep this simple I'm only going to see if living with Both Parent gives a boost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:03.222584Z",
     "start_time": "2019-10-29T19:09:03.209667Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Both Parents       63494\n",
       "Mother             15353\n",
       "Father              1362\n",
       "(Unknown)            698\n",
       "Grandparent(s)       603\n",
       "Guardian(s)          223\n",
       "Foster Parent(s      182\n",
       "Other Relative(      104\n",
       "Agency/Social S       15\n",
       "Alone                  8\n",
       "Spouse/Partner         7\n",
       "Name: LivingWith, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_df.LivingWith.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:03.234745Z",
     "start_time": "2019-10-29T19:09:03.224293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Both Parents'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = get_student_data(3099442)\n",
    "#example = pd.DataFrame(data={'LivingWith': [None, None, None]})\n",
    "example['LivingWith'].value_counts().empty\n",
    "LivingWith = example['LivingWith'].value_counts()\n",
    "LivingWith = None if LivingWith.empty else LivingWith.idxmax()\n",
    "LivingWith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:16.897667Z",
     "start_time": "2019-10-29T19:09:03.236373Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    3140\n",
       "0    1298\n",
       "Name: LivingWithBothParents, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if 'LivingWithBothParents' in X_df.columns:\n",
    "    X_df.drop(['LivingWithBothParents'], axis=1,inplace=True)\n",
    "LivingWithBothParents = pd.DataFrame(columns=['LivingWithBothParents'])\n",
    "for studentID in targets_df.StudentID:\n",
    "    Stu_data = get_student_data(studentID)\n",
    "    LivingWith = Stu_data['LivingWith'].value_counts()\n",
    "    LivingWith = None if LivingWith.empty else LivingWith.idxmax()\n",
    "    if LivingWith is not None:\n",
    "        LivingWith = re.sub('[/() ]','',LivingWith)\n",
    "    LivingWithBothParents = LivingWithBothParents.append({'LivingWithBothParents':LivingWith},ignore_index=True)\n",
    "LivingWithBothParents = pd.get_dummies(LivingWithBothParents.LivingWithBothParents)\n",
    "X_df['LivingWithBothParents'] = LivingWithBothParents.BothParents.copy()\n",
    "X_df.LivingWithBothParents.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Racial/Ethnic Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:16.926290Z",
     "start_time": "2019-10-29T19:09:16.911000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "White               35163\n",
       "Black               14904\n",
       "Multiracial         10877\n",
       "Asian               10500\n",
       "Hispanic             9968\n",
       "Pacific Islander      379\n",
       "American Indian       258\n",
       "Name: RacialEthnicGroup, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_df.RacialEthnicGroup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:16.939758Z",
     "start_time": "2019-10-29T19:09:16.929091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hispanic'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = get_student_data(3099442)\n",
    "#example = pd.DataFrame(data={'Gender': [None, None, None]})\n",
    "example['RacialEthnicGroup'].value_counts().empty\n",
    "RacialEthnicGroup = example['RacialEthnicGroup'].value_counts()\n",
    "RacialEthnicGroup = None if RacialEthnicGroup.empty else RacialEthnicGroup.idxmax()\n",
    "RacialEthnicGroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:30.421870Z",
     "start_time": "2019-10-29T19:09:16.941477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of new RacialEthnicGroup columns: 6\n"
     ]
    }
   ],
   "source": [
    "if len(list(X_df.filter(regex='RacialEthnicGroup_')))>0:\n",
    "    X_df.drop(labels=list(X_df.filter(regex='RacialEthnicGroup_')),\\\n",
    "             axis=1,inplace=True)\n",
    "RacialEthnicGroup = pd.DataFrame(columns=['RacialEthnicGroup'])\n",
    "for studentID in targets_df.StudentID:\n",
    "    Stu_data = get_student_data(studentID)\n",
    "    Race = Stu_data['RacialEthnicGroup'].value_counts()\n",
    "    Race = None if Race.empty else Race.idxmax()\n",
    "    RacialEthnicGroup = RacialEthnicGroup.append({'RacialEthnicGroup':Race},ignore_index=True)\n",
    "df = pd.get_dummies(RacialEthnicGroup.RacialEthnicGroup,\\\n",
    "                                     prefix='RacialEthnicGroup')\n",
    "# Note: picked to drop 'White' ethnic group since it is the largest.\n",
    "X_df = pd.concat([X_df,df.drop(['RacialEthnicGroup_White'],axis=1)],axis=1)\n",
    "print(\"# of new RacialEthnicGroup columns:\",\\\n",
    "      len(list(X_df.filter(regex='RacialEthnicGroup'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set if condition to True to drop all RacialEthnicGroup columns from X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:30.426713Z",
     "start_time": "2019-10-29T19:09:30.423552Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    X_df.drop(labels=list(X_df.filter(regex='RacialEthnicGroup')),\\\n",
    "              axis=1,inplace=True)\n",
    "    print(len(list(X_df.filter(regex='RacialEthnicGroup'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## School Most Attended\n",
    "TestSchoolID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:30.435978Z",
     "start_time": "2019-10-29T19:09:30.428622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example = get_student_data(3099442)\n",
    "example = pd.DataFrame(data={'TestSchoolID': [211, 267, 123]})\n",
    "example['TestSchoolID'].value_counts().empty\n",
    "TestSchoolID = example['TestSchoolID'].value_counts()\n",
    "TestSchoolID = None if TestSchoolID.empty else TestSchoolID.idxmax()\n",
    "TestSchoolID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:43.969537Z",
     "start_time": "2019-10-29T19:09:30.439959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of new MostAttendedSchool columns: 69\n"
     ]
    }
   ],
   "source": [
    "if len(list(X_df.filter(regex='MostAttendedSchool_')))>0:\n",
    "    X_df.drop(labels=list(X_df.filter(regex='MostAttendedSchool_')),\\\n",
    "             axis=1,inplace=True)\n",
    "MostAttendedSchoolID = pd.DataFrame(columns=['MostAttendedSchoolID'])\n",
    "for studentID in targets_df.StudentID:\n",
    "    Stu_data = get_student_data(studentID)\n",
    "    TestSchoolID = Stu_data['TestSchoolID'].value_counts()\n",
    "    TestSchoolID = None if TestSchoolID.empty else TestSchoolID.idxmax()\n",
    "    MostAttendedSchoolID = MostAttendedSchoolID.append({'MostAttendedSchoolID':TestSchoolID},\\\n",
    "                                                       ignore_index=True)\n",
    "df = pd.get_dummies(MostAttendedSchoolID.MostAttendedSchoolID,\\\n",
    "                                     prefix='MostAttendedSchool')\n",
    "# Note: See cells below for rationale for dropping school 275\n",
    "X_df = pd.concat([X_df,df.drop(['MostAttendedSchool_275'],axis=1)],axis=1)\n",
    "print(\"# of new MostAttendedSchool columns:\",\\\n",
    "      len(list(X_df.filter(regex='MostAttendedSchool_'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out which school ID to drop.  I'll drop the largest school that Page Ahead has been serving the longest.  SchoolID's 219, 221, 233, and 275 have been served by Page Ahead since 2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:43.977688Z",
     "start_time": "2019-10-29T19:09:43.971365Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "219    48\n",
       "221    28\n",
       "233    57\n",
       "275    73\n",
       "Name: MostAttendedSchoolID, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MostAttendedSchoolID.MostAttendedSchoolID.value_counts().loc[[219,221,233,275]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:44.008685Z",
     "start_time": "2019-10-29T19:09:43.979321Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TestSchoolID</th>\n",
       "      <th>TestSchoolName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>275</td>\n",
       "      <td>Van Asselt Elementary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     TestSchoolID         TestSchoolName\n",
       "253           275  Van Asselt Elementary"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=map_df[['TestSchoolID','TestSchoolName']].drop_duplicates().sort_values(by=['TestSchoolID'])\n",
    "df[df.TestSchoolID==275]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set if condition to True to drop all MostAttendedSchool columns from X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:44.016398Z",
     "start_time": "2019-10-29T19:09:44.012284Z"
    }
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    X_df.drop(labels=list(X_df.filter(regex='MostAttendedSchool_')),\\\n",
    "              axis=1,inplace=True)\n",
    "    print(len(list(X_df.filter(regex='MostAttendedSchool_'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Y dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:44.031567Z",
     "start_time": "2019-10-29T19:09:44.018501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Y    2879\n",
       "N    1486\n",
       "Name: MetStandard, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df = targets_df[targets_df.StudentID.isin(X_df.StudentID)][['StudentID',\n",
    "                                                              'Score',\n",
    "                                                              'LevelCode',\n",
    "                                                              'MetStandard']]\n",
    "print(len(Y_df))\n",
    "Y_df.MetStandard.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle X_df and Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:44.041495Z",
     "start_time": "2019-10-29T19:09:44.033187Z"
    }
   },
   "outputs": [],
   "source": [
    "X_df.to_pickle('./data/interim/X_df.pkl')\n",
    "Y_df.to_pickle('./data/interim/Y_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-29T19:09:44.060342Z",
     "start_time": "2019-10-29T19:09:44.044268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4438 entries, 0 to 4437\n",
      "Data columns (total 87 columns):\n",
      "StudentID                             4438 non-null object\n",
      "G1_Fall_RIT                           1619 non-null object\n",
      "G1_Winter_RIT                         1254 non-null object\n",
      "G1_Spring_RIT                         3571 non-null object\n",
      "Last_G1_RIT                           3625 non-null object\n",
      "Last_G1_RIT_Season                    3625 non-null object\n",
      "Treatments                            4438 non-null object\n",
      "nTreatments                           4438 non-null int64\n",
      "Female                                4438 non-null uint8\n",
      "HomeLanIsEng                          4438 non-null uint8\n",
      "PrimaryLanIsEng                       4438 non-null uint8\n",
      "LivingWithBothParents                 4438 non-null uint8\n",
      "RacialEthnicGroup_American Indian     4438 non-null uint8\n",
      "RacialEthnicGroup_Asian               4438 non-null uint8\n",
      "RacialEthnicGroup_Black               4438 non-null uint8\n",
      "RacialEthnicGroup_Hispanic            4438 non-null uint8\n",
      "RacialEthnicGroup_Multiracial         4438 non-null uint8\n",
      "RacialEthnicGroup_Pacific Islander    4438 non-null uint8\n",
      "MostAttendedSchool_201                4438 non-null uint8\n",
      "MostAttendedSchool_202                4438 non-null uint8\n",
      "MostAttendedSchool_203                4438 non-null uint8\n",
      "MostAttendedSchool_204                4438 non-null uint8\n",
      "MostAttendedSchool_205                4438 non-null uint8\n",
      "MostAttendedSchool_207                4438 non-null uint8\n",
      "MostAttendedSchool_208                4438 non-null uint8\n",
      "MostAttendedSchool_209                4438 non-null uint8\n",
      "MostAttendedSchool_211                4438 non-null uint8\n",
      "MostAttendedSchool_212                4438 non-null uint8\n",
      "MostAttendedSchool_215                4438 non-null uint8\n",
      "MostAttendedSchool_218                4438 non-null uint8\n",
      "MostAttendedSchool_219                4438 non-null uint8\n",
      "MostAttendedSchool_220                4438 non-null uint8\n",
      "MostAttendedSchool_221                4438 non-null uint8\n",
      "MostAttendedSchool_222                4438 non-null uint8\n",
      "MostAttendedSchool_225                4438 non-null uint8\n",
      "MostAttendedSchool_226                4438 non-null uint8\n",
      "MostAttendedSchool_229                4438 non-null uint8\n",
      "MostAttendedSchool_230                4438 non-null uint8\n",
      "MostAttendedSchool_233                4438 non-null uint8\n",
      "MostAttendedSchool_234                4438 non-null uint8\n",
      "MostAttendedSchool_235                4438 non-null uint8\n",
      "MostAttendedSchool_236                4438 non-null uint8\n",
      "MostAttendedSchool_239                4438 non-null uint8\n",
      "MostAttendedSchool_241                4438 non-null uint8\n",
      "MostAttendedSchool_242                4438 non-null uint8\n",
      "MostAttendedSchool_243                4438 non-null uint8\n",
      "MostAttendedSchool_244                4438 non-null uint8\n",
      "MostAttendedSchool_245                4438 non-null uint8\n",
      "MostAttendedSchool_246                4438 non-null uint8\n",
      "MostAttendedSchool_247                4438 non-null uint8\n",
      "MostAttendedSchool_248                4438 non-null uint8\n",
      "MostAttendedSchool_249                4438 non-null uint8\n",
      "MostAttendedSchool_251                4438 non-null uint8\n",
      "MostAttendedSchool_252                4438 non-null uint8\n",
      "MostAttendedSchool_255                4438 non-null uint8\n",
      "MostAttendedSchool_256                4438 non-null uint8\n",
      "MostAttendedSchool_257                4438 non-null uint8\n",
      "MostAttendedSchool_259                4438 non-null uint8\n",
      "MostAttendedSchool_261                4438 non-null uint8\n",
      "MostAttendedSchool_262                4438 non-null uint8\n",
      "MostAttendedSchool_264                4438 non-null uint8\n",
      "MostAttendedSchool_266                4438 non-null uint8\n",
      "MostAttendedSchool_267                4438 non-null uint8\n",
      "MostAttendedSchool_268                4438 non-null uint8\n",
      "MostAttendedSchool_269                4438 non-null uint8\n",
      "MostAttendedSchool_270                4438 non-null uint8\n",
      "MostAttendedSchool_272                4438 non-null uint8\n",
      "MostAttendedSchool_273                4438 non-null uint8\n",
      "MostAttendedSchool_276                4438 non-null uint8\n",
      "MostAttendedSchool_277                4438 non-null uint8\n",
      "MostAttendedSchool_279                4438 non-null uint8\n",
      "MostAttendedSchool_281                4438 non-null uint8\n",
      "MostAttendedSchool_282                4438 non-null uint8\n",
      "MostAttendedSchool_286                4438 non-null uint8\n",
      "MostAttendedSchool_288                4438 non-null uint8\n",
      "MostAttendedSchool_289                4438 non-null uint8\n",
      "MostAttendedSchool_291                4438 non-null uint8\n",
      "MostAttendedSchool_292                4438 non-null uint8\n",
      "MostAttendedSchool_930                4438 non-null uint8\n",
      "MostAttendedSchool_935                4438 non-null uint8\n",
      "MostAttendedSchool_939                4438 non-null uint8\n",
      "MostAttendedSchool_945                4438 non-null uint8\n",
      "MostAttendedSchool_949                4438 non-null uint8\n",
      "MostAttendedSchool_955                4438 non-null uint8\n",
      "MostAttendedSchool_972                4438 non-null uint8\n",
      "MostAttendedSchool_974                4438 non-null uint8\n",
      "MostAttendedSchool_977                4438 non-null uint8\n",
      "dtypes: int64(1), object(7), uint8(79)\n",
      "memory usage: 619.9+ KB\n"
     ]
    }
   ],
   "source": [
    "X_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
